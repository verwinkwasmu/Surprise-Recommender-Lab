{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will be using the Surprise library. \n",
    "\n",
    "Surprise is an easy-to-use Python scikit for recommender systems that supports both item-item and user-user collaborative filtering\n",
    "\n",
    "Documentation: https://surprise.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install the Surprise, you require a C++ compiler (e.g. Visual studio C++2014) as the library runs on Cython.\n",
    "\n",
    "Simply input into your anaconda terminal:\n",
    "\n",
    "```python\n",
    "pip install scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using anaconda, you can do this as well:\n",
    "\n",
    "```python\n",
    "conda install -c conda-forge scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise import get_dataset_dir, dump\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNBaseline, KNNWithZScore\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed for reproducable results\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise requires three columns in order to work, \n",
    "\n",
    "1. User (raw) ids\n",
    "2. Item (raw) ids\n",
    "3. Ratings\n",
    "\n",
    "You will also require the range of the ratings (E.g. 1-5).\n",
    "\n",
    "Surprise supports the pandas dataframe datatype, so we will perform all processing using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'item_id', 'rating', 'timestamp'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        0       50       5\n",
       "1        0      172       5\n",
       "2        0      133       1\n",
       "3      196      242       3\n",
       "4      186      302       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data from csv\n",
    "df = pd.read_csv(\"user_data.csv\", index_col = 0)\n",
    "print(df.columns)\n",
    "\n",
    "#we don't require timestamp, so drop it\n",
    "df2 = df.drop(\"timestamp\", axis = 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "surprise.dataset.DatasetAutoFolds"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find range of values for rating\n",
    "print(np.sort(df2.rating.unique(), axis = -1))\n",
    "\n",
    "#We require a Reader object, with the rating_scale parameter specified\n",
    "reader = Reader(line_format='user item rating', rating_scale=(1, 5))\n",
    "\n",
    "#Finally, to fully load the dataframe into a Surprise object, we use the load_from_df() method\n",
    "data = Dataset.load_from_df(df2[['user_id', 'item_id', 'rating']], reader)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item to Item collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise contains various algorithms, including SVD, Non-Negative Matrix Factorization and more, but the k-NNs are the only ones that support item-item.\n",
    "    \n",
    "There are a few other parameters we can adjust under our similarity options, but the most important for our purposes is the “user_based” flag. This determines whether we’re computing similarity between users or items. To use the item to item collaborative filtering, set “user_based” to “False”.\n",
    "\n",
    "Source: https://medium.com/@jmcneilkeller/item-item-recommendation-with-surprise-4bf365355d96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSD (Mean Squared Difference similarity) is Surprise’s default similarity option, however we will be using Pearson correlation coefficient instead.\n",
    "\n",
    "Other similarity methods: https://surprise.readthedocs.io/en/stable/similarities.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “min_support” parameter establishes the minimum number of common users necessary for the similarity to not be zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9456008481349131"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson',\n",
    "               'min_support': 5,\n",
    "               'user_based': False} #change this to true for user-user\n",
    "\n",
    "#split your data into train and test\n",
    "train, test = train_test_split(data, test_size=.2)\n",
    "\n",
    "#load your model\n",
    "base1 = KNNBaseline(k=30,sim_options=sim_options)\n",
    "\n",
    "#train\n",
    "base1.fit(train)\n",
    "\n",
    "#predict\n",
    "base1_preds = base1.test(test)\n",
    "\n",
    "#score\n",
    "accuracy.rmse(base1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94421092, 0.94972995, 0.93699652, 0.94479174, 0.9328588 ]),\n",
       " 'fit_time': (5.430090427398682,\n",
       "  5.983448028564453,\n",
       "  5.276017665863037,\n",
       "  5.41839861869812,\n",
       "  9.007898807525635),\n",
       " 'test_time': (9.39434289932251,\n",
       "  8.587968826293945,\n",
       "  7.9939563274383545,\n",
       "  13.728183031082153,\n",
       "  9.03931736946106)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can perform cross-validation on our results as well\n",
    "\n",
    "#5 fold CV\n",
    "cv_results = cross_validate(base1, data , cv=5, measures=['RMSE'])\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941717585317052"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction results returns us a bunch of parameters:\n",
    "    \n",
    "uid – The (raw) user id <br>\n",
    "iid – The (raw) item id <br>\n",
    "r_ui (float) – The true rating rui<br>\n",
    "est (float) – The estimated rating r^ui<br>\n",
    "details (dict) – Stores additional details about the prediction that might be useful for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=803, iid=748, r_ui=1.0, est=2.4486785494098595, details={'actual_k': 22, 'was_impossible': False}),\n",
       " Prediction(uid=228, iid=56, r_ui=2.0, est=3.4100294220574052, details={'actual_k': 11, 'was_impossible': False}),\n",
       " Prediction(uid=13, iid=358, r_ui=3.0, est=1.9768019520380848, details={'actual_k': 30, 'was_impossible': False})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base1_preds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict individual ratings by directly calling the predict() method. <br>\n",
    "\n",
    "Let’s say you’re interested in user 0 and item 50 (make sure they’re in the trainset!), and you know that the true rating rui=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "True\n",
      "True\n",
      "user: 0          item: 50         r_ui = 5.00   est = 3.53   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "#for this example, ill just build the training set from the full data, to make sure user 0 and item 50 are inside\n",
    "\n",
    "sim_options = {'name': 'pearson',\n",
    "               'user_based': False}\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "base2 = KNNBaseline(k=30,sim_options=sim_options)\n",
    "#train\n",
    "base2.fit(trainset)\n",
    "\n",
    "uid = '0'  # raw user id (as in the ratings file). They need to be **strings**!\n",
    "iid = '50'  # raw item id (as in the ratings file). They need to be **strings**!\n",
    "print(trainset.knows_user(0))\n",
    "print(trainset.knows_item(182))\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = base2.predict(uid, iid, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User to user collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could change the user_based option in the KNN algorithim to True, or you can use matrix factorization algorithims to perform User to user collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9311209154993982"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split your data into train and test\n",
    "train, test = train_test_split(data, test_size=.2)\n",
    "\n",
    "#load your model\n",
    "base3 = SVD()\n",
    "\n",
    "#train\n",
    "base3.fit(train)\n",
    "\n",
    "#predict\n",
    "base3_preds = base3.test(test)\n",
    "\n",
    "#score\n",
    "accuracy.rmse(base3_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get the top-N recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "# First train an SVD algorithm\n",
    "data = Dataset.load_from_df(df2[['user_id', 'item_id', 'rating']], reader)\n",
    "train, test = train_test_split(data, test_size=.2)\n",
    "base4 = SVD()\n",
    "base4.fit(train)\n",
    "\n",
    "# Then predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "test = train.build_anti_testset()\n",
    "predictions = base4.test(test)\n",
    "\n",
    "top_n = get_top_n(predictions, n=3)\n",
    "\n",
    "top_n_list = [[uid, [iid for (iid, _) in user_ratings]] for uid, user_ratings in top_n.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title\n",
       "0        1   Toy Story (1995)\n",
       "1        2   GoldenEye (1995)\n",
       "2        3  Four Rooms (1995)\n",
       "3        4  Get Shorty (1995)\n",
       "4        5     Copycat (1995)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv('Movie_Id_Titles.csv', index_col = 0)\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(114, 4.623994833610856), (408, 4.608792707825801), (169, 4.568051500644625)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_titles(predictions_dict,movie_titles_df,user_id):\n",
    "    \n",
    "    '''Convert the raw id of movie titles to the actual name\n",
    "\n",
    "    Args:\n",
    "        predictions_dict: A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "        \n",
    "        movie_titles_df: a dataframe containing the item_id's and titles of movies\n",
    "        \n",
    "        user_id: a numerical value, U, used to denote an unique user\n",
    "        \n",
    "    Returns:\n",
    "    A dataframe containing the top N titles and scores pertaining to user U\n",
    "    '''\n",
    "    \n",
    "    top_recommendations = predictions_dict[user_id]\n",
    "    raw_titles_index = [i[0]-1 for i in top_recommendations]\n",
    "    scores = [i[1] for i in top_recommendations]\n",
    "    temp = movie_titles_df.iloc[raw_titles_index,]\n",
    "    temp['scores'] = scores\n",
    "    #temp = temp.reset_index()\n",
    "    return ('user {} recommendations'.format(user_id),temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User 0 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>Gone with the Wind (1939)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating                            title\n",
       "0        0       50       5                 Star Wars (1977)\n",
       "1        0      172       5  Empire Strikes Back, The (1980)\n",
       "2        0      133       1        Gone with the Wind (1939)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id0_df = df2[df2['user_id'] == 0]\n",
    "pd.merge(id0_df, movie_titles, on=\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('user 0 recommendations',\n",
       "      item_id                                              title    scores\n",
       " 113      114  Wallace & Gromit: The Best of Aardman Animatio...  4.623995\n",
       " 407      408                              Close Shave, A (1995)  4.608793\n",
       " 168      169                         Wrong Trousers, The (1993)  4.568052)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#return top n items from user 0 \n",
    "get_movie_titles(top_n,movie_titles,0)\n",
    "\n",
    "#warning = ignore, as usual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get the k nearest neighbors of a user (or item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the get_neighbors() methods of the algorithm object. This is only relevant for algorithms that use a similarity measure, such as the k-NN algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to convert between raw and inner Ids as Surprise stores them differently. Different algorithims return different Ids as well (some return raw, some return inner). More information here:\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/FAQ.html#raw-inner-note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x1a24a8ea5c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'user_based': False}\n",
    "\n",
    "base5 = KNNBaseline(k=5,sim_options=sim_options)\n",
    "train = data.build_full_trainset()\n",
    "base5.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>588</td>\n",
       "      <td>Beauty and the Beast (1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>174</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>845</td>\n",
       "      <td>That Thing You Do! (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>928</td>\n",
       "      <td>Craft, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>Liar Liar (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>Aladdin (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>523</td>\n",
       "      <td>Cool Hand Luke (1967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>969</td>\n",
       "      <td>Winnie the Pooh and the Blustery Day (1968)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_id                                        title\n",
       "587      588                  Beauty and the Beast (1991)\n",
       "173      174               Raiders of the Lost Ark (1981)\n",
       "844      845                    That Thing You Do! (1996)\n",
       "70        71                        Lion King, The (1994)\n",
       "927      928                            Craft, The (1996)\n",
       "293      294                             Liar Liar (1997)\n",
       "94        95                               Aladdin (1992)\n",
       "522      523                        Cool Hand Luke (1967)\n",
       "968      969  Winnie the Pooh and the Blustery Day (1968)\n",
       "209      210    Indiana Jones and the Last Crusade (1989)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw item id 1 is toy story\n",
    "#raw item id 181 is return of the jedi\n",
    "#convert raw id into inner id\n",
    "inner_id = train.to_inner_iid(1)\n",
    "\n",
    "#get the nearest \n",
    "raw_nearest_id = [train.to_raw_iid(i) for i in base5.get_neighbors(inner_id,10)]\n",
    "\n",
    "#get the indexs for df locating\n",
    "raw_titles_index = [i-1 for i in raw_nearest_id]\n",
    "\n",
    "movie_titles.iloc[raw_titles_index,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
